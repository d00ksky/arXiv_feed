<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/SIawxc5ZzSICl9reau2vWzt0Zk0</id>
  <title>arXiv Query: search_query=all:AI&amp;id_list=&amp;start=0&amp;max_results=15</title>
  <updated>2026-02-19T21:05:48Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:AI&amp;start=0&amp;max_results=15&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>15</opensearch:itemsPerPage>
  <opensearch:totalResults>51180</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/2501.02842v1</id>
    <title>Foundations of GenIR</title>
    <updated>2025-01-06T08:38:29Z</updated>
    <link href="https://arxiv.org/abs/2501.02842v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2501.02842v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The chapter discusses the foundational impact of modern generative AI models on information access (IA) systems. In contrast to traditional AI, the large-scale training and superior data modeling of generative AI models enable them to produce high-quality, human-like responses, which brings brand new opportunities for the development of IA paradigms. In this chapter, we identify and introduce two of them in details, i.e., information generation and information synthesis. Information generation allows AI to create tailored content addressing user needs directly, enhancing user experience with immediate, relevant outputs. Information synthesis leverages the ability of generative AI to integrate and reorganize existing information, providing grounded responses and mitigating issues like model hallucination, which is particularly valuable in scenarios requiring precision and external knowledge. This chapter delves into the foundational aspects of generative models, including architecture, scaling, and training, and discusses their applications in multi-modal scenarios. Additionally, it examines the retrieval-augmented generation paradigm and other methods for corpus modeling and understanding, demonstrating how generative AI can enhance information access systems. It also summarizes potential challenges and fruitful directions for future studies.</summary>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-01-06T08:38:29Z</published>
    <arxiv:comment>Chapter 2 of the book on Information Access in the Era of Generative AI</arxiv:comment>
    <arxiv:primary_category term="cs.IR"/>
    <author>
      <name>Qingyao Ai</name>
    </author>
    <author>
      <name>Jingtao Zhan</name>
    </author>
    <author>
      <name>Yiqun Liu</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2601.16513v1</id>
    <title>Competing Visions of Ethical AI: A Case Study of OpenAI</title>
    <updated>2026-01-23T07:26:45Z</updated>
    <link href="https://arxiv.org/abs/2601.16513v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2601.16513v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Analysis. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. For reproducible results, we have released our code at https://github.com/famous-blue-raincoat/AI_Ethics_Discourse. Results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Conclusions. Implications for governance are presented, along with discussion of ethics-washing practices in industry.</summary>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <published>2026-01-23T07:26:45Z</published>
    <arxiv:comment>iConference 2026</arxiv:comment>
    <arxiv:primary_category term="cs.CY"/>
    <author>
      <name>Melissa Wilfley</name>
    </author>
    <author>
      <name>Mengting Ai</name>
    </author>
    <author>
      <name>Madelyn Rose Sanfilippo</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2308.12400v1</id>
    <title>Towards The Ultimate Brain: Exploring Scientific Discovery with ChatGPT AI</title>
    <updated>2023-07-08T09:59:22Z</updated>
    <link href="https://arxiv.org/abs/2308.12400v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2308.12400v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>This paper presents a novel approach to scientific discovery using an artificial intelligence (AI) environment known as ChatGPT, developed by OpenAI. This is the first paper entirely generated with outputs from ChatGPT. We demonstrate how ChatGPT can be instructed through a gamification environment to define and benchmark hypothetical physical theories. Through this environment, ChatGPT successfully simulates the creation of a new improved model, called GPT$^4$, which combines the concepts of GPT in AI (generative pretrained transformer) and GPT in physics (generalized probabilistic theory). We show that GPT$^4$ can use its built-in mathematical and statistical capabilities to simulate and analyze physical laws and phenomena. As a demonstration of its language capabilities, GPT$^4$ also generates a limerick about itself. Overall, our results demonstrate the promising potential for human-AI collaboration in scientific discovery, as well as the importance of designing systems that effectively integrate AI's capabilities with human intelligence.</summary>
    <category term="cs.OH" scheme="http://arxiv.org/schemas/atom"/>
    <published>2023-07-08T09:59:22Z</published>
    <arxiv:comment>26 pages. To appear in AI Magazine</arxiv:comment>
    <arxiv:primary_category term="cs.OH"/>
    <arxiv:journal_ref>AI Magazine 44, 328 (2023)</arxiv:journal_ref>
    <author>
      <name>Gerardo Adesso</name>
    </author>
    <arxiv:doi>10.1002/aaai.12113</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1002/aaai.12113" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2112.01298v2</id>
    <title>Meaningful human control: actionable properties for AI system development</title>
    <updated>2022-05-19T15:28:01Z</updated>
    <link href="https://arxiv.org/abs/2112.01298v2" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2112.01298v2" rel="related" type="application/pdf" title="pdf"/>
    <summary>How can humans remain in control of artificial intelligence (AI)-based systems designed to perform tasks autonomously? Such systems are increasingly ubiquitous, creating benefits - but also undesirable situations where moral responsibility for their actions cannot be properly attributed to any particular person or group. The concept of meaningful human control has been proposed to address responsibility gaps and mitigate them by establishing conditions that enable a proper attribution of responsibility for humans; however, clear requirements for researchers, designers, and engineers are yet inexistent, making the development of AI-based systems that remain under meaningful human control challenging. In this paper, we address the gap between philosophical theory and engineering practice by identifying, through an iterative process of abductive thinking, four actionable properties for AI-based systems under meaningful human control, which we discuss making use of two applications scenarios: automated vehicles and AI-based hiring. First, a system in which humans and AI algorithms interact should have an explicitly defined domain of morally loaded situations within which the system ought to operate. Second, humans and AI agents within the system should have appropriate and mutually compatible representations. Third, responsibility attributed to a human should be commensurate with that human's ability and authority to control the system. Fourth, there should be explicit links between the actions of the AI agents and actions of humans who are aware of their moral responsibility. We argue that these four properties will support practically-minded professionals to take concrete steps toward designing and engineering for AI systems that facilitate meaningful human control.</summary>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2021-11-25T11:05:37Z</published>
    <arxiv:comment>Preprint. Published AI and Ethics (2022): https://doi.org/10.1007/s43681-022-00167-3</arxiv:comment>
    <arxiv:primary_category term="cs.CY"/>
    <arxiv:journal_ref>AI Ethics (2022)</arxiv:journal_ref>
    <author>
      <name>Luciano Cavalcante Siebert</name>
    </author>
    <author>
      <name>Maria Luce Lupetti</name>
    </author>
    <author>
      <name>Evgeni Aizenberg</name>
    </author>
    <author>
      <name>Niek Beckers</name>
    </author>
    <author>
      <name>Arkady Zgonnikov</name>
    </author>
    <author>
      <name>Herman Veluwenkamp</name>
    </author>
    <author>
      <name>David Abbink</name>
    </author>
    <author>
      <name>Elisa Giaccardi</name>
    </author>
    <author>
      <name>Geert-Jan Houben</name>
    </author>
    <author>
      <name>Catholijn M. Jonker</name>
    </author>
    <author>
      <name>Jeroen van den Hoven</name>
    </author>
    <author>
      <name>Deborah Forster</name>
    </author>
    <author>
      <name>Reginald L. Lagendijk</name>
    </author>
    <arxiv:doi>10.1007/s43681-022-00167-3</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1007/s43681-022-00167-3" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2408.00025v3</id>
    <title>Need of AI in Modern Education: in the Eyes of Explainable AI (xAI)</title>
    <updated>2025-01-02T21:59:22Z</updated>
    <link href="https://arxiv.org/abs/2408.00025v3" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2408.00025v3" rel="related" type="application/pdf" title="pdf"/>
    <summary>Modern Education is not \textit{Modern} without AI. However, AI's complex nature makes understanding and fixing problems challenging. Research worldwide shows that a parent's income greatly influences a child's education. This led us to explore how AI, especially complex models, makes important decisions using Explainable AI tools. Our research uncovered many complexities linked to parental income and offered reasonable explanations for these decisions. However, we also found biases in AI that go against what we want from AI in education: clear transparency and equal access for everyone. These biases can impact families and children's schooling, highlighting the need for better AI solutions that offer fair opportunities to all. This chapter tries to shed light on the complex ways AI operates, especially concerning biases. These are the foundational steps towards better educational policies, which include using AI in ways that are more reliable, accountable, and beneficial for everyone involved.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2024-07-31T08:11:33Z</published>
    <arxiv:comment>Chapter in the book: Blockchain and AI in Shaping the Modern Education System, CRC Press, Taylor &amp; Francis Group, USA</arxiv:comment>
    <arxiv:primary_category term="cs.AI"/>
    <arxiv:journal_ref>Blockchain and AI in Shaping the Modern Education System 2025</arxiv:journal_ref>
    <author>
      <name>Supriya Manna</name>
    </author>
    <author>
      <name>Niladri Sett</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2401.15284v6</id>
    <title>Beyond principlism: Practical strategies for ethical AI use in research practices</title>
    <updated>2025-06-20T02:59:45Z</updated>
    <link href="https://arxiv.org/abs/2401.15284v6" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2401.15284v6" rel="related" type="application/pdf" title="pdf"/>
    <summary>The rapid adoption of generative artificial intelligence (AI) in scientific research, particularly large language models (LLMs), has outpaced the development of ethical guidelines, leading to a "Triple-Too" problem: too many high-level ethical initiatives, too abstract principles lacking contextual and practical relevance, and too much focus on restrictions and risks over benefits and utilities. Existing approaches--principlism (reliance on abstract ethical principles), formalism (rigid application of rules), and technological solutionism (overemphasis on technological fixes)--offer little practical guidance for addressing ethical challenges of AI in scientific research practices. To bridge the gap between abstract principles and day-to-day research practices, a user-centered, realism-inspired approach is proposed here. It outlines five specific goals for ethical AI use: 1) understanding model training and output, including bias mitigation strategies; 2) respecting privacy, confidentiality, and copyright; 3) avoiding plagiarism and policy violations; 4) applying AI beneficially compared to alternatives; and 5) using AI transparently and reproducibly. Each goal is accompanied by actionable strategies and realistic cases of misuse and corrective measures. I argue that ethical AI application requires evaluating its utility against existing alternatives rather than isolated performance metrics. Additionally, I propose documentation guidelines to enhance transparency and reproducibility in AI-assisted research. Moving forward, we need targeted professional development, training programs, and balanced enforcement mechanisms to promote responsible AI use while fostering innovation. By refining these ethical guidelines and adapting them to emerging AI capabilities, we can accelerate scientific progress without compromising research integrity.</summary>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2024-01-27T03:53:25Z</published>
    <arxiv:comment>Published in: AI and Ethics, 2025</arxiv:comment>
    <arxiv:primary_category term="cs.CY"/>
    <arxiv:journal_ref>AI and Ethics, 5, 2719-2731 (2025)</arxiv:journal_ref>
    <author>
      <name>Zhicheng Lin</name>
    </author>
    <arxiv:doi>10.1007/s43681-024-00585-5</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1007/s43681-024-00585-5" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16770v1</id>
    <title>DeBiasMe: De-biasing Human-AI Interactions with Metacognitive AIED (AI in Education) Interventions</title>
    <updated>2025-04-23T14:41:31Z</updated>
    <link href="https://arxiv.org/abs/2504.16770v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2504.16770v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>While generative artificial intelligence (Gen AI) increasingly transforms academic environments, a critical gap exists in understanding and mitigating human biases in AI interactions, such as anchoring and confirmation bias. This position paper advocates for metacognitive AI literacy interventions to help university students critically engage with AI and address biases across the Human-AI interaction workflows. The paper presents the importance of considering (1) metacognitive support with deliberate friction focusing on human bias; (2) bi-directional Human-AI interaction intervention addressing both input formulation and output interpretation; and (3) adaptive scaffolding that responds to diverse user engagement patterns. These frameworks are illustrated through ongoing work on "DeBiasMe," AIED (AI in Education) interventions designed to enhance awareness of cognitive biases while empowering user agency in AI interactions. The paper invites multiple stakeholders to engage in discussions on design and evaluation methods for scaffolding mechanisms, bias visualization, and analysis frameworks. This position contributes to the emerging field of AI-augmented learning by emphasizing the critical role of metacognition in helping students navigate the complex interaction between human, statistical, and systemic biases in AI use while highlighting how cognitive adaptation to AI systems must be explicitly integrated into comprehensive AI literacy frameworks.</summary>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-04-23T14:41:31Z</published>
    <arxiv:comment>Presented at the 2025 ACM Workshop on Human-AI Interaction for Augmented Reasoning, Report Number: CHI25-WS-AUGMENTED-REASONING</arxiv:comment>
    <arxiv:primary_category term="cs.HC"/>
    <arxiv:journal_ref>Proceedings of the 2025 ACM CHI Workshop on Human-AI Interaction for Augmented Reasoning</arxiv:journal_ref>
    <author>
      <name>Chaeyeon Lim</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2211.12434v1</id>
    <title>Expansive Participatory AI: Supporting Dreaming within Inequitable Institutions</title>
    <updated>2022-11-22T17:44:03Z</updated>
    <link href="https://arxiv.org/abs/2211.12434v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2211.12434v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Participatory Artificial Intelligence (PAI) has recently gained interest by researchers as means to inform the design of technology through collective's lived experience. PAI has a greater promise than that of providing useful input to developers, it can contribute to the process of democratizing the design of technology, setting the focus on what should be designed. However, in the process of PAI there existing institutional power dynamics that hinder the realization of expansive dreams and aspirations of the relevant stakeholders. In this work we propose co-design principals for AI that address institutional power dynamics focusing on Participatory AI with youth.</summary>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2022-11-22T17:44:03Z</published>
    <arxiv:comment>3 pages, Human-Centered AI workshop</arxiv:comment>
    <arxiv:primary_category term="cs.HC"/>
    <arxiv:journal_ref>Human-Centered AI workshop (HCAI) 2022, NEURIPS</arxiv:journal_ref>
    <author>
      <name>Michael Alan Chang</name>
    </author>
    <author>
      <name>Shiran Dudy</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.08817v2</id>
    <title>Exploring utilization of generative AI for research and education in data-driven materials science</title>
    <updated>2025-08-04T05:55:53Z</updated>
    <link href="https://arxiv.org/abs/2504.08817v2" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2504.08817v2" rel="related" type="application/pdf" title="pdf"/>
    <summary>Generative AI has recently had a profound impact on various fields, including daily life, research, and education. To explore its efficient utilization in data-driven materials science, we organized a hackathon -- AIMHack2024 -- in July 2024. In this hackathon, researchers from fields such as materials science, information science, bioinformatics, and condensed matter physics worked together to explore how generative AI can facilitate research and education. Based on the results of the hackathon, this paper presents topics related to (1) conducting AI-assisted software trials, (2) building AI tutors for software, and (3) developing GUI applications for software. While generative AI continues to evolve rapidly, this paper provides an early record of its application in data-driven materials science and highlights strategies for integrating AI into research and education.</summary>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.ed-ph" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-04-09T11:15:21Z</published>
    <arxiv:comment>13 pages, 3 figures</arxiv:comment>
    <arxiv:primary_category term="cs.CY"/>
    <author>
      <name>Takahiro Misawa</name>
    </author>
    <author>
      <name>Ai Koizumi</name>
    </author>
    <author>
      <name>Ryo Tamura</name>
    </author>
    <author>
      <name>Kazuyoshi Yoshimi</name>
    </author>
    <arxiv:doi>10.1080/27660400.2025.2535956</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1080/27660400.2025.2535956" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.09138v1</id>
    <title>White-Box AI Model: Next Frontier of Wireless Communications</title>
    <updated>2025-04-12T08:57:17Z</updated>
    <link href="https://arxiv.org/abs/2504.09138v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2504.09138v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>White-box AI (WAI), or explainable AI (XAI) model, a novel tool to achieve the reasoning behind decisions and predictions made by the AI algorithms, makes it more understandable and transparent. It offers a new approach to address key challenges of interpretability and mathematical validation in traditional black-box models. In this paper, WAI-aided wireless communication systems are proposed and investigated thoroughly to utilize the promising capabilities. First, we introduce the fundamental principles of WAI. Then, a detailed comparison between WAI and traditional black-box model is conducted in terms of optimization objectives and architecture design, with a focus on deep neural networks (DNNs) and transformer networks. Furthermore, in contrast to the traditional black-box methods, WAI leverages theory-driven causal modeling and verifiable optimization paths, thereby demonstrating potential advantages in areas such as signal processing and resource allocation. Finally, we outline future research directions for the integration of WAI in wireless communication systems.</summary>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-04-12T08:57:17Z</published>
    <arxiv:primary_category term="cs.IT"/>
    <author>
      <name>Jiayao Yang</name>
    </author>
    <author>
      <name>Jiayi Zhang</name>
    </author>
    <author>
      <name>Bokai Xu</name>
    </author>
    <author>
      <name>Jiakang Zheng</name>
    </author>
    <author>
      <name>Zhilong Liu</name>
    </author>
    <author>
      <name>Ziheng Liu</name>
    </author>
    <author>
      <name>Dusit Niyato</name>
    </author>
    <author>
      <name>MÃ©rouane Debbah</name>
    </author>
    <author>
      <name>Zhu Han</name>
    </author>
    <author>
      <name>Bo Ai</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2311.18252v3</id>
    <title>Privacy and Copyright Protection in Generative AI: A Lifecycle Perspective</title>
    <updated>2024-11-17T12:09:49Z</updated>
    <link href="https://arxiv.org/abs/2311.18252v3" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2311.18252v3" rel="related" type="application/pdf" title="pdf"/>
    <summary>The advent of Generative AI has marked a significant milestone in artificial intelligence, demonstrating remarkable capabilities in generating realistic images, texts, and data patterns. However, these advancements come with heightened concerns over data privacy and copyright infringement, primarily due to the reliance on vast datasets for model training. Traditional approaches like differential privacy, machine unlearning, and data poisoning only offer fragmented solutions to these complex issues. Our paper delves into the multifaceted challenges of privacy and copyright protection within the data lifecycle. We advocate for integrated approaches that combines technical innovation with ethical foresight, holistically addressing these concerns by investigating and devising solutions that are informed by the lifecycle perspective. This work aims to catalyze a broader discussion and inspire concerted efforts towards data privacy and copyright integrity in Generative AI.</summary>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2023-11-30T05:03:08Z</published>
    <arxiv:comment>Accepted by 2024 IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI (CAIN)</arxiv:comment>
    <arxiv:primary_category term="cs.SE"/>
    <arxiv:journal_ref>Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering-Software Engineering for AI. 2024. pp.92-97</arxiv:journal_ref>
    <author>
      <name>Dawen Zhang</name>
    </author>
    <author>
      <name>Boming Xia</name>
    </author>
    <author>
      <name>Yue Liu</name>
    </author>
    <author>
      <name>Xiwei Xu</name>
    </author>
    <author>
      <name>Thong Hoang</name>
    </author>
    <author>
      <name>Zhenchang Xing</name>
    </author>
    <author>
      <name>Mark Staples</name>
    </author>
    <author>
      <name>Qinghua Lu</name>
    </author>
    <author>
      <name>Liming Zhu</name>
    </author>
    <arxiv:doi>10.1145/3644815.3644952</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1145/3644815.3644952" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2509.11056v1</id>
    <title>BERT4beam: Large AI Model Enabled Generalized Beamforming Optimization</title>
    <updated>2025-09-14T02:49:29Z</updated>
    <link href="https://arxiv.org/abs/2509.11056v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2509.11056v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Artificial intelligence (AI) is anticipated to emerge as a pivotal enabler for the forthcoming sixth-generation (6G) wireless communication systems. However, current research efforts regarding large AI models for wireless communications primarily focus on fine-tuning pre-trained large language models (LLMs) for specific tasks. This paper investigates the large-scale AI model designed for beamforming optimization to adapt and generalize to diverse tasks defined by system utilities and scales. We propose a novel framework based on bidirectional encoder representations from transformers (BERT), termed BERT4beam. We aim to formulate the beamforming optimization problem as a token-level sequence learning task, perform tokenization of the channel state information, construct the BERT model, and conduct task-specific pre-training and fine-tuning strategies. Based on the framework, we propose two BERT-based approaches for single-task and multi-task beamforming optimization, respectively. Both approaches are generalizable for varying user scales. Moreover, the former can adapt to varying system utilities and antenna configurations by re-configuring the input and output module of the BERT model, while the latter, termed UBERT, can directly generalize to diverse tasks, due to a finer-grained tokenization strategy. Extensive simulation results demonstrate that the two proposed approaches can achieve near-optimal performance and outperform existing AI models across various beamforming optimization tasks, showcasing strong adaptability and generalizability.</summary>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-09-14T02:49:29Z</published>
    <arxiv:primary_category term="eess.SY"/>
    <author>
      <name>Yuhang Li</name>
    </author>
    <author>
      <name>Yang Lu</name>
    </author>
    <author>
      <name>Wei Chen</name>
    </author>
    <author>
      <name>Bo Ai</name>
    </author>
    <author>
      <name>Zhiguo Ding</name>
    </author>
    <author>
      <name>Dusit Niyato</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.14689v1</id>
    <title>Designing AI Systems that Augment Human Performed vs. Demonstrated Critical Thinking</title>
    <updated>2025-04-20T17:40:28Z</updated>
    <link href="https://arxiv.org/abs/2504.14689v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2504.14689v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>The recent rapid advancement of LLM-based AI systems has accelerated our search and production of information. While the advantages brought by these systems seemingly improve the performance or efficiency of human activities, they do not necessarily enhance human capabilities. Recent research has started to examine the impact of generative AI on individuals' cognitive abilities, especially critical thinking. Based on definitions of critical thinking across psychology and education, this position paper proposes the distinction between demonstrated and performed critical thinking in the era of generative AI and discusses the implication of this distinction in research and development of AI systems that aim to augment human critical thinking.</summary>
    <category term="cs.HC" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-04-20T17:40:28Z</published>
    <arxiv:comment>Presented at the 2025 ACM Workshop on Human-AI Interaction for Augmented Reasoning,</arxiv:comment>
    <arxiv:primary_category term="cs.HC"/>
    <arxiv:journal_ref>Proceedings of the 2025 ACM CHI Workshop on Human-AI Interaction for Augmented Reasoning</arxiv:journal_ref>
    <author>
      <name>Katelyn Xiaoying Mei</name>
    </author>
    <author>
      <name>Nic Weber</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2507.16110v1</id>
    <title>Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization</title>
    <updated>2025-07-21T23:46:11Z</updated>
    <link href="https://arxiv.org/abs/2507.16110v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2507.16110v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Large language models (LLMs) leverage chain-of-thought (CoT) techniques to tackle complex problems, representing a transformative breakthrough in artificial intelligence (AI). However, their reasoning capabilities have primarily been demonstrated in solving math and coding problems, leaving their potential for domain-specific applications-such as battery discovery-largely unexplored. Inspired by the idea that reasoning mirrors a form of guided search, we introduce ChatBattery, a novel agentic framework that integrates domain knowledge to steer LLMs toward more effective reasoning in materials design. Using ChatBattery, we successfully identify, synthesize, and characterize three novel lithium-ion battery cathode materials, which achieve practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this discovery, ChatBattery paves a new path by showing a successful LLM-driven and reasoning-based platform for battery materials invention. This complete AI-driven cycle-from design to synthesis to characterization-demonstrates the transformative potential of AI-driven reasoning in revolutionizing materials discovery.</summary>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-07-21T23:46:11Z</published>
    <arxiv:primary_category term="cs.AI"/>
    <author>
      <name>Shengchao Liu</name>
    </author>
    <author>
      <name>Hannan Xu</name>
    </author>
    <author>
      <name>Yan Ai</name>
    </author>
    <author>
      <name>Huanxin Li</name>
    </author>
    <author>
      <name>Yoshua Bengio</name>
    </author>
    <author>
      <name>Harry Guo</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2412.14538v4</id>
    <title>Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities</title>
    <updated>2025-02-13T07:40:46Z</updated>
    <link href="https://arxiv.org/abs/2412.14538v4" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2412.14538v4" rel="related" type="application/pdf" title="pdf"/>
    <summary>With the growing demand for seamless connectivity and intelligent communication, the integration of artificial intelligence (AI) and sixth-generation (6G) communication networks has emerged as a transformative paradigm. By embedding AI capabilities across various network layers, this integration enables optimized resource allocation, improved efficiency, and enhanced system robust performance, particularly in intricate and dynamic environments. This paper presents a comprehensive overview of AI and communication for 6G networks, with a focus on emphasizing their foundational principles, inherent challenges, and future research opportunities. We first review the integration of AI and communications in the context of 6G, exploring the driving factors behind incorporating AI into wireless communications, as well as the vision for the convergence of AI and 6G. The discourse then transitions to a detailed exposition of the envisioned integration of AI within 6G networks, delineated across three progressive developmental stages. The first stage, AI for Network, focuses on employing AI to augment network performance, optimize efficiency, and enhance user service experiences. The second stage, Network for AI, highlights the role of the network in facilitating and buttressing AI operations and presents key enabling technologies, such as digital twins for AI and semantic communication. In the final stage, AI as a Service, it is anticipated that future 6G networks will innately provide AI functions as services, supporting application scenarios like immersive communication and intelligent industrial robots. In addition, we conduct an in-depth analysis of the critical challenges faced by the integration of AI and communications in 6G. Finally, we outline promising future research opportunities that are expected to drive the development and refinement of AI and 6G communications.</summary>
    <category term="cs.NI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <published>2024-12-19T05:36:34Z</published>
    <arxiv:primary_category term="cs.NI"/>
    <arxiv:journal_ref>Sci China Inf Sci, 2025, 68(7): 171301</arxiv:journal_ref>
    <author>
      <name>Qimei Cui</name>
    </author>
    <author>
      <name>Xiaohu You</name>
    </author>
    <author>
      <name>Ni Wei</name>
    </author>
    <author>
      <name>Guoshun Nan</name>
    </author>
    <author>
      <name>Xuefei Zhang</name>
    </author>
    <author>
      <name>Jianhua Zhang</name>
    </author>
    <author>
      <name>Xinchen Lyu</name>
    </author>
    <author>
      <name>Ming Ai</name>
    </author>
    <author>
      <name>Xiaofeng Tao</name>
    </author>
    <author>
      <name>Zhiyong Feng</name>
    </author>
    <author>
      <name>Ping Zhang</name>
    </author>
    <author>
      <name>Qingqing Wu</name>
    </author>
    <author>
      <name>Meixia Tao</name>
    </author>
    <author>
      <name>Yongming Huang</name>
    </author>
    <author>
      <name>Chongwen Huang</name>
    </author>
    <author>
      <name>Guangyi Liu</name>
    </author>
    <author>
      <name>Chenghui Peng</name>
    </author>
    <author>
      <name>Zhiwen Pan</name>
    </author>
    <author>
      <name>Tao Sun</name>
    </author>
    <author>
      <name>Dusit Niyato</name>
    </author>
    <author>
      <name>Tao Chen</name>
    </author>
    <author>
      <name>Muhammad Khurram Khan</name>
    </author>
    <author>
      <name>Abbas Jamalipour</name>
    </author>
    <author>
      <name>Mohsen Guizani</name>
    </author>
    <author>
      <name>Chau Yuen</name>
    </author>
    <arxiv:doi>10.1007/s11432-024-4337-1</arxiv:doi>
    <link rel="related" href="https://doi.org/10.1007/s11432-024-4337-1" title="doi"/>
  </entry>
</feed>
